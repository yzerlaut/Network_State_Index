{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9476069",
   "metadata": {},
   "source": [
    "# Network State Index -- API demo\n",
    "\n",
    "see: https://github.com/yzerlaut/Network_State_Index\n",
    "\n",
    "We demonstrate the use of the API on the following publicly available dataset:\n",
    "\n",
    "## the \"Visual Coding â€“ Neuropixels\" dataset from the Allen Observatory\n",
    "\n",
    "All details about this dataset and instructions for analysis are available at:\n",
    "\n",
    "https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392f4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some general python / scientific-python modules\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# the Network State Index API, see: https://github.com/yzerlaut/Network_State_Index\n",
    "# install it with: \"pip install git+https://github.com/yzerlaut/Network_State_Index\"\n",
    "import NSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f38353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the data with the \"allensdk\" API\n",
    "# get the \"allensdk\" api with: \"pip install allensdk\"\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "\n",
    "# now let's define a cache repository for the data: by default ~/Downloads/ecephys_cache_dir\n",
    "# insure that you have a \"Downloads\" repository in your home directory (/!\\ non-english systems) or update below\n",
    "data_directory = os.path.join(os.path.expanduser('~'), 'Downloads', 'ecephys_cache_dir')\n",
    "manifest_path = os.path.join(data_directory, \"manifest.json\")\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)\n",
    "all_sessions = cache.get_session_table() # get all sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68248afc",
   "metadata": {},
   "source": [
    "### We restrict the analysis to:\n",
    "\n",
    "    - wild type / wild type strain\n",
    "    - male\n",
    "    - recordings including V1 (\"VISp\")\n",
    "    - \"Brain Observatory 1.1\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2cb729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "--> Number of sessions with the desired characteristics: 16------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# let's filter the sessions according to the above criteria\n",
    "sessions = all_sessions[(all_sessions.sex == 'M') & \\\n",
    "                        (all_sessions.full_genotype.str.find('wt/wt') > -1) & \\\n",
    "                        (all_sessions.session_type == 'brain_observatory_1.1') & \\\n",
    "                        (['VISp' in acronyms for acronyms in all_sessions.ecephys_structure_acronyms])]\n",
    "print(30*'--'+'\\n--> Number of sessions with the desired characteristics: ' + str(len(sessions))+30*'--')\n",
    "# sessions.head() # uncomment to see how they look"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389ff9a",
   "metadata": {},
   "source": [
    "## Minimal demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP = np.random.randn(100)\n",
    "pLFP = NSI.compute_pLFP(LFP,\n",
    "                       freqs=np.linspace(50, 300, 10))\n",
    "NSI = NSI.compute_NSI(pLFP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5cadf5",
   "metadata": {},
   "source": [
    "## In a more structured way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d955ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yann.zerlaut/miniconda3/lib/python3.9/site-packages/allensdk/brain_observatory/ecephys/ecephys_session.py:1348: UserWarning: Session includes invalid time intervals that could be accessed with the attribute 'invalid_times',Spikes within these intervals are invalid and may need to be excluded from the analysis.\n",
      "  warnings.warn(\"Session includes invalid time intervals that could \"\n"
     ]
    }
   ],
   "source": [
    "# let's do things in a bit more structured way\n",
    "class Data:\n",
    "    \"\"\"\n",
    "    an object to load, format and process the data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, session_index):\n",
    "        \"\"\"\n",
    "        loading data according to the index of the \"sessions\" above\n",
    "        \"\"\"\n",
    "        # we load a single session\n",
    "        session = cache.get_session_data(sessions.index.values[session_index])\n",
    "\n",
    "        # let's fetch the V1 probe --> always on \"probeC\"\n",
    "        probe_id = session.probes[session.probes.description == 'probeC'].index.values[0]\n",
    "\n",
    "        # let's fetch the lfp data for that probe and that session\n",
    "        LFP_all_channels = session.get_lfp(probe_id)\n",
    "        self.lfp_sampling_rate = session.probes.lfp_sampling_rate[probe_id]\n",
    "\n",
    "        # let's fetch the channels corresponding to V1\n",
    "        self.V1_channel_ids = session.channels[(session.channels.probe_id == probe_id) & \\\n",
    "                         (session.channels.ecephys_structure_acronym.isin(['VISp']))].index.values\n",
    "        self.lfp_slice_V1 = LFP_all_channels.sel(channel=slice(np.min(self.V1_channel_ids), np.max(self.V1_channel_ids)))\n",
    "        self.Nchannels_V1 = len(self.V1_channel_ids)\n",
    "        self.t_LFP = self.lfp_slice_V1.time\n",
    "        self.LFP = np.array(self.lfp_slice_V1)\n",
    "        \n",
    "        # using the LFP timestamps to get starting and duration times\n",
    "        self.tstart, self.duration = float(self.t_LFP[0]), float(self.t_LFP[-1]-self.t_LFP[0])\n",
    "\n",
    "        # let's fetch the isolated single units in V1\n",
    "        V1_units = session.units[session.units.ecephys_structure_acronym == 'VISp'] # V1==VISp\n",
    "        self.V1_RASTER = [session.spike_times[i] for i in V1_units.index] # RASTER = a list over units of spiketimes\n",
    "        \n",
    "        # let's fetch the running speed\n",
    "        self.t_running_speed = .5*(session.running_speed.start_time.values+session.running_speed.end_time.values)\n",
    "        self.running_speed = session.running_speed.velocity\n",
    "\n",
    "        # let's compute the population activity from the spikes\n",
    "        self.compute_pop_act() # you can recall this functions with different bins/smoothing        \n",
    "        \n",
    "    def compute_pop_act(self, \n",
    "                        pop_act_bin=5e-3,\n",
    "                        pop_act_smoothing=40e-3):\n",
    "        \"\"\"\n",
    "        we bin spikes to compute population activity\n",
    "        \"\"\"\n",
    "        t_pop_act = self.tstart+np.arange(int(self.duration/pop_act_bin)+1)*pop_act_bin\n",
    "        pop_act = np.zeros(len(t_pop_act)-1)\n",
    "\n",
    "        for i, spikes in enumerate(self.V1_RASTER):\n",
    "            pop_act += np.histogram(spikes, bins=t_pop_act)[0]\n",
    "        pop_act /= (len(self.V1_RASTER)*pop_act_bin)\n",
    "\n",
    "        self.t_pop_act = .5*(t_pop_act[1:]+t_pop_act[:-1])\n",
    "        self.pop_act = NSI.gaussian_filter1d(pop_act, int(pop_act_smoothing/pop_act_bin))\n",
    "        \n",
    "    def compute_pLFP(self, \n",
    "                     channelID=None,\n",
    "                     t0=0, \n",
    "                     duration=20):\n",
    "        \"\"\"\n",
    "        ------------------------------\n",
    "            HERE we use the NSI API\n",
    "        ------------------------------\n",
    "        by default on a zoom of the data, not the entire trace as this can be long\n",
    "        call: \"data.compute_pLFP(duration=data.duration)\" to have it on the full trace\n",
    "        \n",
    "        pLFP in microvolts (uV)\n",
    "        \"\"\"\n",
    "        lfp_slice = self.lfp_slice_V1.sel(time=slice(t0,t0+duration))\n",
    "        \n",
    "        if channelID is not None:\n",
    "            self.t_pLFP, self.pLFP = NSI.compute_pLFP(1e6*np.array(lfp_slice)[:,channelID],\n",
    "                                                      self.lfp_sampling_rate)\n",
    "        else:\n",
    "            # sum over all channels\n",
    "            self.t_pLFP, self.pLFP = NSI.compute_pLFP(1e6*np.array(lfp_slice).T,\n",
    "                                                      self.lfp_sampling_rate)\n",
    "        self.t_pLFP += t0\n",
    "\n",
    "    def plot(self, quantity, t0=0, duration=np.inf,\n",
    "             ax=None,\n",
    "             color='k', lw=1):\n",
    "        \"\"\"\n",
    "        quantity as a string (e.g. \"pLFP\" or \"running_speed\")\n",
    "        \"\"\"\n",
    "        if hasattr(self, quantity):\n",
    "            if ax is None:\n",
    "                fig, ax =plt.subplots(1, figsize=(8,3))\n",
    "            else:\n",
    "                fig = None\n",
    "            cond = (getattr(self, 't_'+quantity)>t0) & (getattr(self, 't_'+quantity)<(t0+duration))\n",
    "            ax.plot(getattr(self, 't_'+quantity)[cond], getattr(self, quantity)[cond], color=color, lw=lw)\n",
    "            return fig, ax\n",
    "        else:\n",
    "            print('%s not an attribute of data' % quantity)\n",
    "\n",
    "    \n",
    "data = Data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4fce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.plot('running_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d94ed0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11768162, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data.lfp_slice_V1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a82c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "def plot_sample_data(data,\n",
    "                     time_points=[100, 1000],\n",
    "                     duration=2., \n",
    "                     pop_act_bin=5e-3):\n",
    "\n",
    "    fig, AX_full = plt.subplots(5,len(time_points), figsize=(3*len(time_points), 6))\n",
    "    if len(time_points)==1:\n",
    "        AX_full = [AX_full]\n",
    "        \n",
    "    YLIMS = [[np.inf, -np.inf] for i in range(len(AX_full))]\n",
    "    for t0, AX in zip(time_points, AX_full.T):\n",
    "        \n",
    "        # raster plot\n",
    "        for i, spikes in enumerate(data.V1_RASTER):\n",
    "            cond = (spikes>t0) & (spikes<(t0+duration))\n",
    "            AX[0].plot(spikes[cond], i+0*spikes[cond], 'ko', ms=1.5)\n",
    "\n",
    "        # pop act. plot\n",
    "        data.plot('pop_act', t0=t0, duration=duration, ax=AX[1])\n",
    "        \n",
    "        # LFP plot\n",
    "        lfp_slice = data.lfp_slice_V1.sel(time=slice(t0,t0+duration))\n",
    "        for i in range(len(lfp_slice.channel.values)):\n",
    "            AX[2].plot(lfp_slice.time, 1e3*lfp_slice.sel(channel=lfp_slice.channel[i]), \n",
    "                       lw=0.2, color=plt.cm.copper(1-i/(len(lfp_slice.channel.values)-1)))\n",
    "        \n",
    "        # speed plot\n",
    "        data.plot('running_speed', t0=t0, duration=duration, ax=AX[4])\n",
    "\n",
    "        # pLFP plot\n",
    "        data.compute_pLFP(t0=t0-2, duration=duration+4, channelID=1)\n",
    "        data.plot('pLFP', t0=t0, duration=duration, ax=AX[3])\n",
    "        \n",
    "        # labelling axes and setting the same limes\n",
    "        for j, label, ax in zip(range(len(AX)), \n",
    "                                ['units', 'rate (Hz)', 'LFP (mV)', 'pLFP (uV)', 'run. speed\\n(cm/s)'], AX):\n",
    "            if ax in AX_full.T[0]:\n",
    "                ax.set_ylabel(label)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_xlim([t0,t0+duration])\n",
    "            YLIMS[j] = [np.min([AX[j].get_ylim()[0], YLIMS[j][0]]),\n",
    "                        np.max([AX[j].get_ylim()[1], YLIMS[j][1]])]\n",
    "        AX[0].set_title('$t_0$=%.1fs' % (t0), size='small')\n",
    "        \n",
    "    for AX in AX_full.T:\n",
    "        for j in range(len(AX)):\n",
    "            try:\n",
    "                AX[j].set_ylim(YLIMS[j])\n",
    "            except BaseException:\n",
    "                pass\n",
    "    for t0, AX in zip(time_points, AX_full.T):\n",
    "        AX[0].plot([t0,t0+0.2], YLIMS[0][1]*np.ones(2), 'k-', lw=1)\n",
    "        AX[0].annotate('200ms', (t0, AX[0].get_ylim()[1]))\n",
    "                        \n",
    "plot_sample_data(data, time_points=[7199.5, 7531, 7421.5]) # session 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "342ce772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([198.   , 198.005, 198.01 , ..., 212.565, 212.57 , 212.575])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0, duration = 200, 10\n",
    "data.compute_pLFP(t0=t0-2, duration=duration+4, channelID=19)\n",
    "data.t_pLFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.compute_pLFP(t0=t0-2, duration=duration+4, channelID=19)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
